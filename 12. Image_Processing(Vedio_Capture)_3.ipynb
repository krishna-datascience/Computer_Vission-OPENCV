{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Live Sketch', frame)\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[[[199 194 215]\n",
      "  [199 194 215]\n",
      "  [197 194 215]\n",
      "  ...\n",
      "  [144 146 155]\n",
      "  [149 147 166]\n",
      "  [148 146 165]]\n",
      "\n",
      " [[194 194 214]\n",
      "  [195 195 215]\n",
      "  [193 195 215]\n",
      "  ...\n",
      "  [142 144 157]\n",
      "  [146 144 162]\n",
      "  [147 145 163]]\n",
      "\n",
      " [[186 194 209]\n",
      "  [187 195 210]\n",
      "  [192 197 213]\n",
      "  ...\n",
      "  [140 142 153]\n",
      "  [142 144 157]\n",
      "  [146 147 161]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 41  35  33]\n",
      "  [ 42  36  34]\n",
      "  [ 39  37  37]\n",
      "  ...\n",
      "  [ 84 105 112]\n",
      "  [ 85 106 113]\n",
      "  [ 89 111 118]]\n",
      "\n",
      " [[ 42  33  34]\n",
      "  [ 41  32  33]\n",
      "  [ 40  34  32]\n",
      "  ...\n",
      "  [ 90 104 112]\n",
      "  [ 86 105 110]\n",
      "  [ 87 106 111]]\n",
      "\n",
      " [[ 48  40  47]\n",
      "  [ 45  36  44]\n",
      "  [ 48  35  43]\n",
      "  ...\n",
      "  [ 91 104 117]\n",
      "  [ 92 105 120]\n",
      "  [ 92 105 120]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    print(ret)\n",
    "    print(frame)\n",
    "else:\n",
    "    ret = False\n",
    "\n",
    "img1 = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#plt.imshow(img1)\n",
    "plt.title('Image Camera-1')\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling resizing and interplotation\n",
    "import cv2\n",
    "import numpy as pd\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Let's make the size of our image 3/4 of it's original size\n",
    "img_scaled = cv2.resize(img, None, fx=0.75, fy=0.75)\n",
    "cv2.imshow('Scaling -Linear Interplotation', img_scaled)\n",
    "cv2.waitKey()\n",
    "\n",
    "#Let's doubled the size of our image\n",
    "img_scaled1 = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interplotation', img_scaled1)\n",
    "cv2.waitKey()\n",
    "\n",
    "#Let's skew the re-sizing by setting exact dimensions\n",
    "img_scaled2 = cv2.resize(img, (900, 400), interpolation=cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled2)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Edge Detection\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\",0)\n",
    "\n",
    "\n",
    "height,width = img.shape\n",
    "\n",
    "\n",
    "#Extract slop edges\n",
    "sobel_x = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=5)\n",
    "sobel_y = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=5)\n",
    "\n",
    "\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Sobel X Image',sobel_x)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Sobel Y Image',sobel_y)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "sobel_Or = cv2.bitwise_or(sobel_x,sobel_y)\n",
    "cv2.imshow('Sobel or Image',sobel_Or)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "laplacian = cv2.Laplacian(img, cv2.CV_64F)\n",
    "cv2.imshow('Laplacian Image',laplacian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Canny Edge detection uses gradiant values as thresholds\n",
    "canny = cv2.Canny(img, 20, 170)\n",
    "cv2.imshow('Canny Edge', canny)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  LIVE SKETCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def sketch(image):\n",
    "    #Convert image to grayscale\n",
    "    img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    #Cleanup image using gaussian blur\n",
    "    img_gray_blur = cv2.GaussianBlur(img_gray,(5,5),0)\n",
    "\n",
    "    #Extract Edges\n",
    "    canny_edges = cv2.Canny(img_gray_blur, 10, 70)\n",
    "\n",
    "    #Do an invert binarize the image\n",
    "    ret, mask = cv2.threshold(canny_edges,70,255,cv2.THRESH_BINARY)\n",
    "    return mask\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow('Our Live Sketch', sketch(frame))\n",
    "    if cv2.waitKey(1)==13:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image resize using image Pyramid\n",
    "import cv2\n",
    "import numpy as pd\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "smaller = cv2.pyrDown(img)\n",
    "larger = cv2.pyrUp(img)\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.imshow('Smaller', smaller)\n",
    "cv2.imshow('Larger', larger)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image Cropping\n",
    "import cv2\n",
    "import numpy as pd\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "#Let's get the starting pixel coordinates(top left, of cropping rectangle)\n",
    "\n",
    "start_row, start_col = int(height*.25), int(width*.25)\n",
    "\n",
    "#Let's get the ending pixel coordinates (bottom right)\n",
    "\n",
    "end_row, end_col = int(height*.75), int(width*.75)\n",
    "\n",
    "#Simply use the indexing to crop the image\n",
    "\n",
    "cropped = img[start_row:end_row, start_col:end_col]\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.imshow('Cropped', cropped)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Arithmetic\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('lena.jpg')\n",
    "\n",
    "cv2.imshow('Original', img)\n",
    "cv2.waitKey(0)\n",
    "M = np.ones(img.shape, dtype=\"uint8\") * 150\n",
    "\n",
    "added = cv2.add(img, M)\n",
    "cv2.imshow('Added', added)\n",
    "\n",
    "subtracted = cv2.subtract(img, M)\n",
    "cv2.imshow('Subtract', subtracted)\n",
    "\n",
    "mul = cv2.multiply(img,M)\n",
    "cv2.imshow('MUl',mul)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bitwise Operation\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "square = np.zeros((300,300), np.uint8)\n",
    "\n",
    "cv2.rectangle(square, (50,50), (250,250), 255, -1)\n",
    "cv2.imshow(\"Square\", square)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#making as eclipse\n",
    "\n",
    "ellipse = np.zeros((300,300), np.uint8)\n",
    "cv2.ellipse(ellipse, (150,150), (150,150), 30, 0, 180, 255, -1)\n",
    "cv2.imshow(\"Ellipse\", ellipse)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "And = cv2.bitwise_and(square, ellipse)\n",
    "cv2.imshow(\"AND\", And)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Or = cv2.bitwise_or(square, ellipse)\n",
    "cv2.imshow(\"OR\", Or)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Xor = cv2.bitwise_xor(square, ellipse)\n",
    "cv2.imshow(\"XOR\", Xor)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "Not = cv2.bitwise_not(square)\n",
    "cv2.imshow(\"NOT\", Not)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image Blurring\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Averaging done by convolving the image with a normalize box filter\n",
    "#This takes the pixels under the box and replace the central element\n",
    "#Box size needs to odd and positive\n",
    "blur = cv2.blur(img, (3,3))\n",
    "cv2.imshow('Blur Image',blur)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Insted of using Box filter use gaussinan kernel\n",
    "Gaussian = cv2.GaussianBlur(img, (7,7), 0)\n",
    "cv2.imshow('Gaussian Blur Image',Gaussian)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Take median of all the pixels under kernel area and central\n",
    "#element is replaced with this median value\n",
    "median = cv2.medianBlur(img, 5)\n",
    "cv2.imshow('Median Blur Image',median)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Bilateral is very effective in nose removal\n",
    "bilateral = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "cv2.imshow('Bilateral Blur Image',bilateral)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Denoising Non-Local Denoising\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "dst = cv2.fastNlMeansDenoisingColored(img, None, 6, 6, 7, 21)\n",
    "\n",
    "cv2.imshow(\"Fast Mean Denosing\",dst)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Image Sharpening\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread(\"lena.jpg\")\n",
    "cv2.imshow('Original Image',img)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "#Create our sharpening kernel, we don't normalize since the\n",
    "#the values in the matrix sum to 1\n",
    "kernel_sharpening = np.array([[-1,-1,-1],\n",
    "                              [-1,9,-1],\n",
    "                              [-1,-1,-1]])\n",
    "\n",
    "#applying different kernel to the different image\n",
    "sharpened = cv2.filter2D(img, -1, kernel_sharpening)\n",
    "\n",
    "cv2.imshow('Image sharpening', sharpened)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
